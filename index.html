<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Hoseong Jung</title>

    <meta name="author" content="Hoseong Jung">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Hoseong Jung
                </p>
                <p>I'm a PhD student in the <a href="https://gsai.snu.ac.kr/en/#none">Interdisciplinary Program in Artificial Intelligence</a>  at Seoul National University, working at <a href="https://larr.snu.ac.kr/">Lab for Autonomous Robotics Research (LARR)</a> under the guidance of Prof. <a href="https://larr.snu.ac.kr/">H. Jin Kim</a>.
                </p>
                <p>
                  My research focuses on cooperative intelligence within multi-agent embodied systems. </br>
                  Before joining LARR, I was a research officer at the Defense AI Center of the <a href="https://www.add.re.kr/eps">Agency for Defense Development (ADD)</a>. </br>
                  I completed my bachelor's degree in <a href="https://ece.snu.ac.kr/en">Electrical and Computer Engineering</a> at the Seoul National University. </br>
                  I hope my research leads to assistant robots that bring care and support to children and people with disabilities.
                </p>
                <p style="text-align:center">
                  <a href="mailto:ghtjdaleka@snu.ac.kr">Email</a> &nbsp;/&nbsp;
                  <a href="data/HoseongJung-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/HoseongJung-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=0OmDQAYAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/junghoseong98">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/hoseong-jung-39092b2a5/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/junghoseong">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/HoseongJung.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/HoseongJung.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>News</h2>
                  <ul>
                    <li><b>[Jun 2025]</b> Presented our work at the <i> RSS 2025 workshop on Leveraging Implicit Methods for Aerial Autonomy</i>, in LA.</li>
                    <li><b>[Oct 2024]</b> Presented our RA-L paper and late breaking results at <i>IROS 2024</i>, held in Abu Dhabi.</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr onmouseout="RSS_workshop_stop()" onmouseover="RSS_workshop_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='RSS_workshop_image'>
              <img src='images/RSS_workshop_before.png' width="160"></div>
            <video width=100% height 100% muted autoplay loop>
              <source src="images/RSS_workshop_after.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>
          <script type="text/javascript">
            function RSS_workshop_start() {
              document.getElementById('RSS_workshop_image').style.opacity = "1";
            }

            function RSS_workshop_stop() {
              document.getElementById('RSS_workshop_image').style.opacity = "0";
            }
            RSS_workshop_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Temporal Action Representation Learning for Tactical Resource Control and Subsequent Maneuver Generation</span>
          <br>
          <strong>Hoseong Jung</strong>,
          Sungil Son,
          Daesol Cho,
          Jonghae Park,
          Changhyun Choi,
          H. Jin Kim
          <br>
          <div><em>IEEE International Conference on Robotics and Automation (ICRA)</em>, 2026</div>
          <div><em>RSS workshop on Leveraging Implicit Methods for Aerial Autonomy</em>, 2025</div>
          <br>
          <a href="https://im4rob.github.io/attend/papers/8_Temporal_Action_Representati.pdf">paper</a>
          <p></p>
          <p>
          In this paper, we introduce a temporal action contrastive learning approach that facilitates semantic alignment between resource control and tactical maneuvers. </p>
        </td>
      </tr>

      <tr onmouseout="mdt_stop()" onmouseover="mdt_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='mdt_image'>
              <img src='images/MDT_after.jpg' width="160"></div>
            <img src='images/MDT_before.jpg' width="160">
          </div>
          <script type="text/javascript">
            function mdt_start() {
              document.getElementById('mdt_image').style.opacity = "1";
            }

            function mdt_stop() {
              document.getElementById('mdt_image').style.opacity = "0";
            }
            mdt_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Maneuver-Conditioned Decision Transformer for Tactical in-Flight Decision-Making</span>
          <br>
          <strong>Hoseong Jung</strong>,
          Yong-Duk Kim,
          Youngjung Kim
          <br>
          <em>IEEE Robotics and Automation Letters</em>, 2024
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/10505781">paper</a>
          <p></p>
          <p>
          In this paper, we explore the offline reinforcement learning framework for tactical air combat. 
          </p>
        </td>
      </tr>

      <tr onmouseout="access_stop()" onmouseover="access_start()">
        <td style="padding:16px;width:20%;vertical-align:middle">
          <div class="one">
            <div class="two" id='access_image'>
              <img src='images/Access_after.jpg' width="160"></div>
            <img src='images/Access_before.jpg' width="160">
          </div>
          <script type="text/javascript">
            function access_start() {
              document.getElementById('access_image').style.opacity = "1";
            }

            function access_stop() {
              document.getElementById('access_image').style.opacity = "0";
            }
            access_stop()
          </script>
        </td>
        <td style="padding:8px;width:80%;vertical-align:middle">
          <span class="papertitle">Deep Reinforcement Learning-Based Air-to-Air Combat Maneuver Generation in a Realistic Environment</span>
          <br>
          Jung Ho Bae,
          <strong>Hoseong Jung</strong>,
          Seogbong Kim,
          Sungho Kim,
          Yong-Duk Kim
          <br>
          <em>IEEE Access</em>, 2023
          <br>
          <a href="https://ieeexplore.ieee.org/abstract/document/10072404">paper</a>
          <p></p>
          <p>
          In this paper, we propose a deep reinforcement learning-based framework for developing a model capable of performing within visual range (WVR) air-to-air combat under the conditions of a partially observable Markov decision process (POMDP) with insufficient information. 
          </p>
        </td>
      </tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Projects</h2>
              </td>
            </tr>

            <tr onmouseout="aiace_stop()" onmouseover="aiace_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='aiace_image'>
                    <img src='images/AIACE_after.jpg' width="160"></div>
                  <img src='images/AIACE_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function aiace_start() {
                    document.getElementById('aiace_image').style.opacity = "1";
                  }
      
                  function access_stop() {
                    document.getElementById('aiace_image').style.opacity = "0";
                  }
                  aiace_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <span class="papertitle">AI for Air Combat Engagement</span>
                <br>
                Agency for Defense Development, 2022 - 2023
                <br>
                <p></p>
                <p>
                In this project, we develop both heuristic-based and learning-based agent performing within visual range (WVR) air-to-air combat. 
                </p>
              </td>
            </tr>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Awards</h2>
                  <ul>
                    <li><b>[Scholarship]</b> Hyundai Motor Chung Mong-Koo Foundation (Aug 2025 â€“ Present)</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
